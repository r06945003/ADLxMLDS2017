{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, LeakyReLU, Activation, Reshape, Input\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Lambda, Concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "K.set_learning_phase(False) \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dick(x):\n",
    "    x = K.expand_dims(x, axis=1)\n",
    "    x = K.expand_dims(x, axis=2)\n",
    "    x = K.tile(x, [1, 4, 4, 1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def wasserstein(y_true, y_pred):\n",
    "\n",
    "    # return K.mean(y_true * y_pred) / K.mean(y_true)\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "class dcgan():\n",
    "    def __init__(self):\n",
    "        self.dis_depth = 64\n",
    "        self.gen_depth = 512\n",
    "        self.alpha = 0.2\n",
    "        self.dim = 4\n",
    "        self.batch = 64\n",
    "        self.epochs = 300\n",
    "        \n",
    "    def getmodelweight(self):\n",
    "    \n",
    "        #generator weights\n",
    "        \n",
    "        truncate_normal = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.02, seed=None)\n",
    "        \n",
    "        self.s_dense = Dense(256, kernel_initializer=truncate_normal, name='sd0')\n",
    "        self.s_leak = LeakyReLU(self.alpha, name='slk')\n",
    "        \n",
    "        #4 4 512\n",
    "        self.g_dense_1 = Dense(self.dim*self.dim*self.gen_depth, kernel_initializer=truncate_normal, name='gd1')\n",
    "        self.g_conv_1 = Conv2DTranspose(int(self.gen_depth/2), 5, kernel_initializer=truncate_normal, strides=2, padding='same', name='gc1')\n",
    "        self.g_conv_2 = Conv2DTranspose(int(self.gen_depth/4), 5, kernel_initializer=truncate_normal, strides=2, padding='same', name='gc2')\n",
    "        self.g_conv_3 = Conv2DTranspose(int(self.gen_depth/8), 5, kernel_initializer=truncate_normal, strides=2, padding='same', name='gc3')\n",
    "        self.g_conv_4 = Conv2DTranspose(3, 5, kernel_initializer=truncate_normal, strides=2, padding='same', name='gc4')\n",
    "        \n",
    "        self.g_batch_1 = BatchNormalization(momentum=0.9, epsilon=1e-5, name='gb1')\n",
    "        self.g_batch_2 = BatchNormalization(momentum=0.9, epsilon=1e-5, name='gb2')\n",
    "        self.g_batch_3 = BatchNormalization(momentum=0.9, epsilon=1e-5, name='gb3')\n",
    "        self.g_batch_4 = BatchNormalization(momentum=0.9, epsilon=1e-5, name='gb4')\n",
    "        \n",
    "        self.g_resap = Reshape((self.dim, self.dim, self.gen_depth), name='gres')\n",
    "        self.g_relu = Activation('relu', name='greu')\n",
    "        self.g_leak = LeakyReLU(self.alpha, name='glk')\n",
    "        self.g_tanh = Activation('tanh', name='gtan')\n",
    "        self.g_concat = Concatenate(axis=-1, name='gcon')\n",
    "        \n",
    "        #discriminator weights\n",
    "    \n",
    "        #32 32 64\n",
    "        self.d_conv_1 = Conv2D(self.dis_depth*1, 5, strides=2, kernel_initializer=truncate_normal, padding='same', name='dc1') \n",
    "        self.d_conv_2 = Conv2D(self.dis_depth*2, 5, strides=2, kernel_initializer=truncate_normal, padding='same', name='dc2')\n",
    "        self.d_conv_3 = Conv2D(self.dis_depth*4, 5, strides=2, kernel_initializer=truncate_normal, padding='same', name='dc3')\n",
    "        self.d_conv_4 = Conv2D(self.dis_depth*8, 5, strides=2, kernel_initializer=truncate_normal, padding='same', name='dc4')\n",
    "        self.d_conv_5 = Conv2D(self.dis_depth*8, 1, strides=1, kernel_initializer=truncate_normal, padding='same', name='dc5')\n",
    "        \n",
    "        self.d_leak = LeakyReLU(self.alpha, name='dlk')\n",
    "        self.d_lamb = Lambda(dick, name='dlm')\n",
    "        self.d_concat = Concatenate(axis=-1, name='dc')\n",
    "        self.d_flat = Flatten()\n",
    "        self.d_dense = Dense(1, kernel_initializer=truncate_normal)\n",
    "        self.d_sig = Activation('sigmoid')\n",
    "        \n",
    "    def getgenerator(self, input_1, input_2):\n",
    "        \n",
    "        #generator network\n",
    "        self.gn_dense_0 = self.s_leak(input_2)\n",
    "        \n",
    "        self.gn_concat = self.g_concat([input_1, self.gn_dense_0])\n",
    "        \n",
    "        self.gn_dense_1 = self.g_dense_1(self.gn_concat)\n",
    "        self.gn_batch_1 = self.g_batch_1(self.gn_dense_1)\n",
    "        self.gn_resap_1 = self.g_resap(self.gn_batch_1)\n",
    "        \n",
    "        self.gn_conv_1 = self.g_conv_1(self.gn_resap_1)\n",
    "        self.gn_batch_2 = self.g_batch_2(self.gn_conv_1)\n",
    "        self.gn_relu_1 = self.g_relu(self.gn_batch_2)\n",
    "        \n",
    "        self.gn_conv_2 = self.g_conv_2(self.gn_relu_1)\n",
    "        self.gn_batch_3 = self.g_batch_3(self.gn_conv_2)\n",
    "        self.gn_relu_2 = self.g_relu(self.gn_batch_3)\n",
    "        \n",
    "        self.gn_conv_3 = self.g_conv_3(self.gn_relu_2)\n",
    "        self.gn_batch_4 = self.g_batch_4(self.gn_conv_3)\n",
    "        self.gn_relu_3 = self.g_relu(self.gn_batch_4)\n",
    "        \n",
    "        self.gn_conv_4 = self.g_conv_4(self.gn_relu_3)\n",
    "        self.gn_tanh = self.g_tanh(self.gn_conv_4)\n",
    "        \n",
    "        return self.gn_tanh\n",
    "        \n",
    "    def getdiscriminator(self, input_1, input_2):\n",
    "        \n",
    "        #discriminator network\n",
    "        \n",
    "        #32 32 64\n",
    "        self.dn_conv_1 = self.d_conv_1(input_1)\n",
    "        self.dn_leak_1 = self.d_leak(self.dn_conv_1)\n",
    "        \n",
    "        #16 16 128\n",
    "        self.dn_conv_2 = self.d_conv_2(self.dn_leak_1)\n",
    "        self.dn_leak_2 = self.d_leak(self.dn_conv_2)\n",
    "        \n",
    "        #8 8 256\n",
    "        self.dn_conv_3 = self.d_conv_3(self.dn_leak_2)\n",
    "        self.dn_leak_3 = self.d_leak(self.dn_conv_3)\n",
    "        \n",
    "        #4 4 512\n",
    "        self.dn_conv_4 = self.d_conv_4(self.dn_leak_3)\n",
    "        self.dn_leak_4 = self.d_leak(self.dn_conv_4)\n",
    "        \n",
    "        self.dn_dense_0 = self.s_leak(input_2)\n",
    "        self.dn_lamba = self.d_lamb(self.dn_dense_0)\n",
    "        self.dn_concat = self.d_concat([self.dn_leak_4, self.dn_lamba])\n",
    "        \n",
    "        self.dn_conv_5 = self.d_conv_5(self.dn_concat)\n",
    "        self.dn_leak_5 = self.d_leak(self.dn_conv_5)\n",
    "        \n",
    "        self.dn_flat = self.d_flat(self.dn_leak_5)\n",
    "        \n",
    "        self.dn_dense = self.d_dense(self.dn_flat)\n",
    "        return self.dn_dense\n",
    "        \n",
    "    def getmodels(self):\n",
    "        \n",
    "        input_shape1 = (64, 64, 3)\n",
    "        input_shape2 = (2400,)\n",
    "        input_shape3 = (100,)\n",
    "\n",
    "        self.input_1 = Input(shape=input_shape1) #image\n",
    "        self.input_2 = Input(shape=input_shape2) #seq vec\n",
    "        self.input_3 = Input(shape=input_shape3) #random noise\n",
    "        \n",
    "        self.generator = self.getgenerator(self.input_3, self.input_2)\n",
    "        self.discriminator = self.getdiscriminator(self.input_1, self.input_2)\n",
    "        \n",
    "        self.generatorModel = Model(inputs=[self.input_3, self.input_2], outputs=[self.generator])\n",
    "        self.discriminatorModel = Model(inputs=[self.input_1, self.input_2], outputs=[self.discriminator])\n",
    "        \n",
    "        self.generatorModel.summary()\n",
    "        self.discriminatorModel.summary()\n",
    "        \n",
    "        self.netD_real_input = Input(shape=(64, 64, 3))\n",
    "        self.netD_wrong_input = Input(shape=(64, 64, 3))\n",
    "        self.seq2vec = Input(shape=(2400,))\n",
    "        self.wrong_seq2vec = Input(shape=(2400,))\n",
    "        self.noisev = Input(shape=(100,))\n",
    "        \n",
    "        self.netD_fake_input = self.generatorModel([self.noisev, self.seq2vec])\n",
    "\n",
    "        self.epsilon_input = K.placeholder(shape=(None,1,1,1))\n",
    "        self.epsilont_input = K.placeholder(shape=(None,1))\n",
    "        self.netD_mixed_input = Input(shape=(64, 64, 3),\n",
    "            tensor=self.epsilon_input * self.netD_real_input + (1-self.epsilon_input) * (self.netD_fake_input+self.netD_wrong_input + self.netD_real_input)/3)\n",
    "        \n",
    "        self.mixed_seq2vec = Input(shape=(2400,),\n",
    "            tensor=self.epsilont_input * self.seq2vec + (1-self.epsilont_input) * (self.seq2vec + self.seq2vec + self.wrong_seq2vec)/3)\n",
    "        \n",
    "        self.loss_real = K.mean(self.discriminatorModel([self.netD_real_input, self.seq2vec]))\n",
    "        self.loss_wrong = K.mean(self.discriminatorModel([self.netD_wrong_input, self.seq2vec]))\n",
    "        self.loss_wrong2 = K.mean(self.discriminatorModel([self.netD_real_input, self.wrong_seq2vec]))\n",
    "        self.loss_fake = K.mean(self.discriminatorModel([self.netD_fake_input, self.seq2vec]))\n",
    "\n",
    "        self.grad_mixed = K.gradients(self.discriminatorModel([self.netD_mixed_input, self.mixed_seq2vec]), [self.netD_mixed_input])[0]\n",
    "        self.norm_grad_mixed = K.sqrt(K.sum(K.square(self.grad_mixed), axis=[1,2,3]))\n",
    "        self.grad_penalty = K.mean(K.square(self.norm_grad_mixed -1))\n",
    "\n",
    "        self.d_loss = (self.loss_fake + self.loss_wrong + self.loss_wrong2)/3 - self.loss_real + 10 * self.grad_penalty\n",
    "\n",
    "\n",
    "        self.d_training_updates = Adam(lr=1e-4, beta_1=0.0, beta_2=0.9).get_updates(self.discriminatorModel.trainable_weights,[], self.d_loss)\n",
    "        self.netD_train = K.function([self.netD_real_input, self.netD_wrong_input, self.seq2vec, self.wrong_seq2vec, self.noisev, self.epsilon_input, self.epsilont_input],\n",
    "                                [self.d_loss],    \n",
    "                                self.d_training_updates)\n",
    "        \n",
    "        self.g_loss = -self.loss_fake \n",
    "        self.g_training_updates = Adam(lr=1e-4, beta_1=0.0, beta_2=0.9).get_updates(self.generatorModel.trainable_weights,[], self.g_loss)\n",
    "        self.netG_train = K.function([self.noisev, self.seq2vec], [self.g_loss], self.g_training_updates)\n",
    "        \n",
    "    def loadseq2vec(self):\n",
    "        self.seq2vec = np.load('../../../GAN/sequenceVector.npy')\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        vecp = np.load('test.npy')\n",
    "        bigdata = np.load('../../../GAN/data2.npy')\n",
    "        \n",
    "        for k in range(0, self.epochs):\n",
    "            \n",
    "            ite=0\n",
    "            while ite<len(bigdata):\n",
    "                data = bigdata[ite:(ite+self.batch)]\n",
    "                vecs = self.seq2vec[ite:(ite+self.batch)]\n",
    "                wdata = [data[(x+1)%len(data)] for x in range(len(data))]\n",
    "                wvecs = [vecs[(x+1)%len(vecs)] for x in range(len(vecs))]\n",
    "                \n",
    "                noise = np.random.normal(0, 1.0, size=[len(data), 100])\n",
    "                e1 = np.random.uniform(0,1,[len(data),1,1,1])\n",
    "                e2  = np.reshape(e1,[len(data),1])\n",
    "                for l in range(5):\n",
    "                    errD,  = self.netD_train([data, wdata, vecs, wvecs, noise, e1, e2])\n",
    "                    errD = np.mean(errD)\n",
    "\n",
    "                for l in range(1):\n",
    "                    errG, = self.netG_train([noise, vecs])\n",
    "                    errG = np.mean(errG)\n",
    "\n",
    "                print(errD, errG)\n",
    "                ite+=self.batch\n",
    "                \n",
    "            noise = np.random.normal(0, 1.0, size=[len(data), 100])\n",
    "            images_fake = self.generatorModel.predict([noise[:36], vecp])\n",
    "            width = 6\n",
    "            new_im = Image.new('RGB', (64*width,64*width))\n",
    "            for ii in range(width):\n",
    "                for jj in range(width):\n",
    "                    index=ii*width+jj\n",
    "                    image = (images_fake[index]/2+0.5)*255\n",
    "                    image = image.astype(np.uint8)\n",
    "                    new_im.paste(Image.fromarray(image,\"RGB\"), (64*ii,64*jj))\n",
    "            filename = \"images_adam/fakeFace%d.png\"%k\n",
    "            new_im.save(filename)\n",
    "            self.generatorModel.save(\"model_adam/generator%d.h5\"%k)\n",
    "            self.discriminatorModel.save(\"model_adam/discriminator%d.h5\"%k)\n",
    "            ite += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 2400)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "slk (LeakyReLU)                 (None, 2400)         0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gcon (Concatenate)              (None, 2500)         0           input_13[0][0]                   \n",
      "                                                                 slk[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gd1 (Dense)                     (None, 8192)         20488192    gcon[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gb1 (BatchNormalization)        (None, 8192)         32768       gd1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gres (Reshape)                  (None, 4, 4, 512)    0           gb1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gc1 (Conv2DTranspose)           (None, 8, 8, 256)    3277056     gres[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gb2 (BatchNormalization)        (None, 8, 8, 256)    1024        gc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "greu (Activation)               multiple             0           gb2[0][0]                        \n",
      "                                                                 gb3[0][0]                        \n",
      "                                                                 gb4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gc2 (Conv2DTranspose)           (None, 16, 16, 128)  819328      greu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gb3 (BatchNormalization)        (None, 16, 16, 128)  512         gc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gc3 (Conv2DTranspose)           (None, 32, 32, 64)   204864      greu[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gb4 (BatchNormalization)        (None, 32, 32, 64)   256         gc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gc4 (Conv2DTranspose)           (None, 64, 64, 3)    4803        greu[2][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gtan (Activation)               (None, 64, 64, 3)    0           gc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 24,828,803\n",
      "Trainable params: 24,811,523\n",
      "Non-trainable params: 17,280\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dc1 (Conv2D)                    (None, 32, 32, 64)   4864        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dlk (LeakyReLU)                 multiple             0           dc1[0][0]                        \n",
      "                                                                 dc2[0][0]                        \n",
      "                                                                 dc3[0][0]                        \n",
      "                                                                 dc4[0][0]                        \n",
      "                                                                 dc5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dc2 (Conv2D)                    (None, 16, 16, 128)  204928      dlk[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dc3 (Conv2D)                    (None, 8, 8, 256)    819456      dlk[1][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 2400)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dc4 (Conv2D)                    (None, 4, 4, 512)    3277312     dlk[2][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "slk (LeakyReLU)                 (None, 2400)         0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dlm (Lambda)                    (None, 4, 4, 2400)   0           slk[1][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dc (Concatenate)                (None, 4, 4, 2912)   0           dlk[3][0]                        \n",
      "                                                                 dlm[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dc5 (Conv2D)                    (None, 4, 4, 512)    1491456     dc[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 8192)         0           dlk[4][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            8193        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,806,209\n",
      "Trainable params: 5,806,209\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dcgan = dcgan()\n",
    "dcgan.getmodelweight()\n",
    "dcgan.getmodels()\n",
    "dcgan.loadseq2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a15138d3304e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-2a7fe23d22a6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0me2\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                     \u001b[0merrD\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetD_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                     \u001b[0merrD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "dcgan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
