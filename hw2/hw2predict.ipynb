{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "from random import randint\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "\n",
    "from tensorflow.python.ops.rnn_cell import GRUCell\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell\n",
    "from tensorflow.python.ops.rnn_cell import MultiRNNCell\n",
    "from tensorflow.python.ops.rnn_cell import DropoutWrapper, ResidualWrapper\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.util import nest\n",
    "\n",
    "from tensorflow.contrib.seq2seq.python.ops import attention_wrapper\n",
    "from tensorflow.contrib.seq2seq.python.ops import beam_search_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "6061\n",
      "6062\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/MLDS_hw2_data/\"\n",
    "\n",
    "testdir = \"testing_data/feat/\"\n",
    "\n",
    "testfiles = os.listdir(path+testdir)\n",
    "\n",
    "testdata = {}\n",
    "videos = []\n",
    "for i in range(0,len(testfiles)):\n",
    "    name = str.split(testfiles[i],\".\")[0]+'.'+str.split(testfiles[i],\".\")[1]\n",
    "    testdata[name] = np.load(path+testdir+testfiles[i])\n",
    "    videos.append(name)\n",
    "print(len(testdata))\n",
    "\n",
    "testjsonfile = open(path+\"testing_label.json\",\"r\")\n",
    "\n",
    "testjson = json.load(testjsonfile)\n",
    "\n",
    "encodeWords = np.load(\"encodeWords.npy\").item()\n",
    "decodeWords = np.load(\"decodeWords.npy\").item()\n",
    "decodeWords[-1] = \"\"\n",
    "print(len(encodeWords))\n",
    "print(len(decodeWords))\n",
    "\n",
    "max_seq_length = 21\n",
    "\n",
    "def getStr(ints):\n",
    "    sentence = ' '.join([decodeWords[int(x)] for x in ints])\n",
    "    sentence = sentence.replace('<BOS> ','').replace(' <EOS>', '')\n",
    "    return sentence\n",
    "\n",
    "def getTestDataSets():\n",
    "    x_data = np.zeros((100,80,4096),dtype=\"float32\")\n",
    "\n",
    "    i = 0\n",
    "    for x in testjson:\n",
    "        name = x[\"id\"]\n",
    "        temp = testdata[name]\n",
    "        x_data[i] = temp\n",
    "        i=i+1\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think it's OK!\n"
     ]
    }
   ],
   "source": [
    "unit = 512\n",
    "inputs = tf.placeholder(tf.float32,[None,80,4096])\n",
    "batch_size = tf.shape(inputs)[0]\n",
    "beam_width = 3\n",
    "start_tokens = tf.fill([batch_size], encodeWords[\"<BOS>\"])\n",
    "\n",
    "def lstm_cell():\n",
    "  return tf.contrib.rnn.BasicLSTMCell(unit)\n",
    "\n",
    "encoder_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(2)])\n",
    "\n",
    "encoder_outputs, encoder_state = tf.nn.dynamic_rnn(encoder_cell, inputs, dtype=tf.float32)\n",
    "\n",
    "tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(encoder_outputs, beam_width)\n",
    "\n",
    "tiled_encoder_state = tf.contrib.seq2seq.tile_batch(encoder_state, beam_width)\n",
    "\n",
    "tiled_sequence_length = tf.contrib.seq2seq.tile_batch(tf.fill([batch_size],80), beam_width)\n",
    "\n",
    "batch_size_beam = tf.shape(tiled_encoder_outputs)[0]\n",
    "\n",
    "attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units=unit, memory=tiled_encoder_outputs, memory_sequence_length = tiled_sequence_length)\n",
    "\n",
    "decoder_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(2)])\n",
    "\n",
    "attention_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism)\n",
    "\n",
    "initial_state = attention_cell.zero_state(dtype=tf.float32, batch_size=batch_size * beam_width)\n",
    "initial_state = initial_state.clone(cell_state=tiled_encoder_state) \n",
    "\n",
    "embedding = tf.Variable(tf.random_uniform([len(encodeWords), unit], -0.1, 0.1, dtype=tf.float32))\n",
    "\n",
    "output_projection_layer = Dense(len(encodeWords), use_bias=False)\n",
    "\n",
    "#train\n",
    "#helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding, start_tokens, encodeWords[\"<EOS>\"])\n",
    "decoder = tf.contrib.seq2seq.BeamSearchDecoder(attention_cell, embedding, start_tokens, encodeWords[\"<EOS>\"], initial_state, beam_width, output_layer=output_projection_layer,\n",
    "        length_penalty_weight=0.0)\n",
    "decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, maximum_iterations=max_seq_length, impute_finished=False)\n",
    "\n",
    "outputs = decoder_outputs.predicted_ids[:,:,0]\n",
    "\n",
    "print(\"I think it's OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model200.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "saver.restore(sess, \"model200.ckpt\")\n",
    "\n",
    "x_data = getTestDataSets()\n",
    "predict = sess.run([outputs], feed_dict={inputs: x_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = [getStr(x) for x in predict[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answer.txt\",\"w\")\n",
    "for i in range(0,len(ans)):\n",
    "    f.write(videos[i]+\",\"+ans[i]+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
